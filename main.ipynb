{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fcce9a-bc73-4985-b926-08aca73de37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 08:49:01.196460: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-12 08:49:01.197170: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-12 08:49:01.202627: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-12 08:49:01.216623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-12 08:49:01.238714: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-12 08:49:01.245524: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-12 08:49:01.262146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-12 08:49:02.536627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a09f17c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-12 08:49:13.023100: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(lr_img, hr_img):\n",
    "    hr_img = tf.image.central_crop(hr_img, central_fraction=0.5)\n",
    "    hr_img = tf.image.resize(hr_img, (224, 224))\n",
    "    lr_img = tf.image.resize(hr_img, (112, 112))\n",
    "    lr_img = tf.image.resize(lr_img, (224, 224))\n",
    "    return lr_img, hr_img\n",
    "\n",
    "def load_div2k_dataset(num_samples=100):\n",
    "    dataset = tfds.load('div2k', split='train', as_supervised=True)\n",
    "    dataset = dataset.take(num_samples)\n",
    "    lr_images = []\n",
    "    hr_images = []\n",
    "    for lr_img, hr_img in tfds.as_numpy(dataset):\n",
    "        lr_img, hr_img = preprocess_image(lr_img, hr_img)\n",
    "        lr_images.append(lr_img)\n",
    "        hr_images.append(hr_img)\n",
    "    return np.array(lr_images), np.array(hr_images)\n",
    "\n",
    "lr_images, hr_images = load_div2k_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5aa9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(lr_images, hr_images, train_ratio=0.6, val_ratio=0.2):\n",
    "    lr_train, lr_temp, hr_train, hr_temp = train_test_split(lr_images, hr_images, train_size=train_ratio)\n",
    "    val_size = val_ratio / (1 - train_ratio)\n",
    "    lr_val, lr_test, hr_val, hr_test = train_test_split(lr_temp, hr_temp, train_size=val_size)\n",
    "    return lr_train, lr_val, lr_test, hr_train, hr_val, hr_test\n",
    "\n",
    "lr_train, lr_val, lr_test, hr_train, hr_val, hr_test = split_data(lr_images, hr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d4aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr_metric(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3073b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_srcnn_model():\n",
    "    input_layer = layers.Input(shape=(224, 224, 3))\n",
    "    x = layers.Conv2D(64, (9, 9), activation='relu', padding='same')(input_layer)\n",
    "    x = layers.Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = layers.Conv2D(3, (5, 5), activation='linear', padding='same')(x)\n",
    "    output_layer = layers.Add()([input_layer, x])\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='mean_squared_error', metrics=[psnr_metric])\n",
    "    return model\n",
    "\n",
    "srcnn_model = build_srcnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d4c4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miljan/Image-Super-Resolution/my_env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def build_srcnn_reg_model(reg_factor=1e-4):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (9, 9), activation='relu', padding='same', kernel_regularizer=regularizers.l2(reg_factor), input_shape=(224, 224, 3)),\n",
    "        layers.Conv2D(32, (5, 5), activation='relu', padding='same', kernel_regularizer=regularizers.l2(reg_factor)),\n",
    "        layers.Conv2D(3, (5, 5), activation='linear', padding='same')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=[psnr_metric])\n",
    "    return model\n",
    "\n",
    "srcnn_reg_model = build_srcnn_reg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e5bfde5-e11c-4c41-b4e7-4814efba8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_srcnn_tanh_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(224, 224, 3)),\n",
    "        layers.Lambda(lambda x: (x / 127.5) - 1.0),  # Normalize to [-1, 1]\n",
    "        layers.Conv2D(64, (9, 9), activation='relu', padding='same'),\n",
    "        layers.Conv2D(32, (5, 5), activation='relu', padding='same'),\n",
    "        layers.Conv2D(3, (5, 5), activation='linear', padding='same'),\n",
    "        layers.Lambda(lambda x: (x + 1.0) * 127.5)  # De-normalize to [0, 255]\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=[psnr_metric])\n",
    "    return model\n",
    "\n",
    "srcnn_tanh_model = build_srcnn_tanh_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd12b37-7358-4411-ac76-4ae49bd5d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_srcnn_batchnorm_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (9, 9), padding='same', input_shape=(224, 224, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Conv2D(32, (5, 5), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Conv2D(3, (5, 5), activation='linear', padding='same')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=[psnr_metric])\n",
    "    return model\n",
    "\n",
    "srcnn_batchnorm_model = build_srcnn_batchnorm_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2dcc9d3-1673-46c7-b3e8-1fc75d42fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, lr_train, hr_train, lr_val, hr_val, epochs=100, batch_size=2):\n",
    "    history = model.fit(lr_train, hr_train, validation_data=(lr_val, hr_val), epochs=epochs, batch_size=batch_size)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9413c5-0e59-4efb-92ea-09de424baf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 277ms/step - loss: 508.3853 - psnr_metric: 21.6800 - val_loss: 320.0070 - val_psnr_metric: 23.5477\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 306ms/step - loss: 449.1425 - psnr_metric: 22.7041 - val_loss: 308.1211 - val_psnr_metric: 23.7276\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - loss: 416.3849 - psnr_metric: 23.1645 - val_loss: 297.9072 - val_psnr_metric: 23.8837\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - loss: 468.5750 - psnr_metric: 22.6112 - val_loss: 290.9860 - val_psnr_metric: 23.9923\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 298ms/step - loss: 356.6518 - psnr_metric: 23.5823 - val_loss: 286.4189 - val_psnr_metric: 24.0635\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 276ms/step - loss: 402.5572 - psnr_metric: 23.2822 - val_loss: 282.2367 - val_psnr_metric: 24.1360\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 269ms/step - loss: 414.2563 - psnr_metric: 23.0621 - val_loss: 278.3961 - val_psnr_metric: 24.2062\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 255ms/step - loss: 358.0688 - psnr_metric: 23.7211 - val_loss: 275.2274 - val_psnr_metric: 24.2621\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 273ms/step - loss: 395.0867 - psnr_metric: 23.5707 - val_loss: 282.8049 - val_psnr_metric: 24.0993\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 277ms/step - loss: 389.8859 - psnr_metric: 23.6085 - val_loss: 275.5133 - val_psnr_metric: 24.2389\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 287ms/step - loss: 335.6756 - psnr_metric: 24.2753 - val_loss: 272.0897 - val_psnr_metric: 24.3147\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 291ms/step - loss: 366.9185 - psnr_metric: 23.8634 - val_loss: 271.1949 - val_psnr_metric: 24.3309\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 313ms/step - loss: 357.2621 - psnr_metric: 23.7392 - val_loss: 269.3162 - val_psnr_metric: 24.3658\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 301ms/step - loss: 337.4842 - psnr_metric: 24.2857 - val_loss: 269.1836 - val_psnr_metric: 24.3683\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 311ms/step - loss: 366.7436 - psnr_metric: 23.6411 - val_loss: 267.6189 - val_psnr_metric: 24.3952\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 358ms/step - loss: 359.0979 - psnr_metric: 23.8629 - val_loss: 267.5332 - val_psnr_metric: 24.3921\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - loss: 368.3894 - psnr_metric: 23.8396 - val_loss: 266.1456 - val_psnr_metric: 24.4207\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 321ms/step - loss: 345.6345 - psnr_metric: 24.3814 - val_loss: 265.3197 - val_psnr_metric: 24.4373\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 323ms/step - loss: 312.7230 - psnr_metric: 24.1286 - val_loss: 264.7768 - val_psnr_metric: 24.4465\n",
      "Epoch 20/100\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 267ms/step - loss: 303.0949 - psnr_metric: 24.7180"
     ]
    }
   ],
   "source": [
    "history_srcnn = train_model(srcnn_model, lr_train, hr_train, lr_val, hr_val)\n",
    "history_srcnn_reg = train_model(srcnn_reg_model, lr_train, hr_train, lr_val, hr_val)\n",
    "history_srcnn_tanh = train_model(srcnn_tanh_model, lr_train, hr_train, lr_val, hr_val)\n",
    "history_srcnn_batchnorm = train_model(srcnn_batchnorm_model, lr_train, hr_train, lr_val, hr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438a6a7-50d2-4cae-8e59-13b60ef440a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, lr_test, hr_test):\n",
    "    psnr_values = []\n",
    "    for lr_img, hr_img in zip(lr_test, hr_test):\n",
    "        sr_img = model.predict(np.expand_dims(lr_img, axis=0))\n",
    "        psnr_value = tf.image.psnr(hr_img, sr_img[0], max_val=255.0).numpy()\n",
    "        psnr_values.append(psnr_value)\n",
    "    return np.mean(psnr_values)\n",
    "\n",
    "psnr_srcnn = evaluate_model(srcnn_model, lr_test, hr_test)\n",
    "psnr_srcnn_reg = evaluate_model(srcnn_reg_model, lr_test, hr_test)\n",
    "psnr_srcnn_tanh = evaluate_model(srcnn_tanh_model, lr_test, hr_test)\n",
    "psnr_srcnn_batchnorm = evaluate_model(srcnn_batchnorm_model, lr_test, hr_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
